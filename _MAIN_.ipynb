{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEKDEcZY0Ed9"
      },
      "source": [
        "# **Machine learning for low-resource NLP**: Advancing AI for Linguistic Inclusion\n",
        "Cross-lingual transfer learning and pseudo-labeling for multilingual named entity recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents  \n",
        "1. [Imports](#imports)  \n",
        "2. [Project Setup](#project-setup)  \n",
        "   - 2.1 [Configuration](#configuration)  \n",
        "   - 2.2 [Reproducibility](#reproducibility)  \n",
        "3. [Data Processing](#data-processing)  \n",
        "   - 3.1 [Download Data](#download-data)  \n",
        "   - 3.2 [NER Dataset](#ner-dataset)  \n",
        "   - 3.3 [Dataloaders](#dataloaders)  \n",
        "4. [Model Architecture](#model-architecture)  \n",
        "5. [Training Utilities](#training-utilities)  \n",
        "   - 5.1 [Optimizer Setup](#optimizer-setup)  \n",
        "   - 5.2 [Evaluation Metric](#evaluation-metric)  \n",
        "6. [Training Pipeline](#training-pipeline)  \n",
        "   - 6.1 [Training Loop](#training-loop)  \n",
        "   - 6.2 [Validation](#validation)  \n",
        "7. [Experiments](#experiments)  \n",
        "   - 7.1 [Baseline Models](#baseline-models)  \n",
        "   - 7.2 [Cross-Lingual Transfer](#cross-lingual-transfer-learning)  \n",
        "   - 7.3 [Iterative Pseudo-Labeling](#iterative-pseudo-labeling)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wu7-PcR2xzI"
      },
      "source": [
        "### 1. Imports <a id='imports'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMkZmRoX2xLR"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import BertTokenizerFast\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import ConcatDataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Project Setup <a id='project-setup'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.1 Configuration <a id='configuration'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseConfig:\n",
        "    RANDOM_STATE          = 42\n",
        "    DEVICE                = torch.device(\"cuda\")\n",
        "\n",
        "    # Data\n",
        "    low_resource_langs    = [\"mg\", \"fo\", \"co\", \"hsb\", \"bh\", \"cv\"]\n",
        "    high_resource_langs   = [\"id\", \"da\", \"it\", \"pl\", \"hi\", \"tr\"]\n",
        "\n",
        "    NUM_TAGS              = 7\n",
        "    BATCH_SIZE            = 32\n",
        "    MAX_SEQ_LEN           = 80\n",
        "\n",
        "class TrainConfig(BaseConfig):\n",
        "    EPOCHS                = 20\n",
        "    PATIENCE              = 5\n",
        "    BERT_LEARNING_RATE    = 0.00003\n",
        "    LSTM_LEARNING_RATE    = 0.005\n",
        "    CRF_LEARNING_RATE     = 0.00005\n",
        "    WEIGHT_DECAY          = 0.02\n",
        "\n",
        "class FineTuneConfig(BaseConfig):\n",
        "    EPOCHS                = 15\n",
        "    PATIENCE              = 3\n",
        "    BERT_LEARNING_RATE    = 0.00002\n",
        "    LSTM_LEARNING_RATE    = 0.003\n",
        "    CRF_LEARNING_RATE     = 0.00003\n",
        "\n",
        "class PseudoLabelingConfig(BaseConfig):\n",
        "    EPOCHS                = 25\n",
        "    PATIENCE              = 5\n",
        "    BERT_LEARNING_RATE    = 0.00002\n",
        "    LSTM_LEARNING_RATE    = 0.003\n",
        "    CRF_LEARNING_RATE     = 0.00003\n",
        "\n",
        "    CONFIDENCE_QUANTILE   = 0.965\n",
        "    PSEUDO_DELAY          = 8\n",
        "    ENTROPY_THRESHOLD     = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5TPSU9HgdWq"
      },
      "source": [
        "#### 2.2 Reproducibility <a id='reproducibility'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4KsqUJuTgpSX"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(BaseConfig.RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_7UwDji3Cfo"
      },
      "source": [
        "### 3. Data Processing <a id='data-processing'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1 Download Data <a id='download-data'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "83jA6h2-zZiy",
        "outputId": "c5b149b6-ec47-41da-ee95-c5980771a869"
      },
      "outputs": [],
      "source": [
        "def load_wikiann_datasets(language_codes, cutoff=None):\n",
        "\n",
        "    language_data = {}\n",
        "    for lang in language_codes:\n",
        "        \n",
        "        # Load raw data from hugging face\n",
        "        lang_dataset = load_dataset(\"unimelb-nlp/wikiann\", name=lang)\n",
        "\n",
        "        # Get data from different splits and combine\n",
        "        train_df = pd.DataFrame(lang_dataset[\"train\"])\n",
        "        val_df = pd.DataFrame(lang_dataset[\"validation\"])\n",
        "        test_df = pd.DataFrame(lang_dataset[\"test\"])\n",
        "\n",
        "        complete_df = pd.concat([train_df, val_df, test_df]).reset_index(drop=True)\n",
        "        complete_df = complete_df.head(cutoff) if cutoff else complete_df\n",
        "\n",
        "        # Split data into new train/val/test splits\n",
        "        train, temp = train_test_split(complete_df, test_size=0.2, random_state=BaseConfig.RANDOM_STATE)\n",
        "        val, test = train_test_split(temp, test_size=0.5, random_state=BaseConfig.RANDOM_STATE)\n",
        "\n",
        "        language_data[lang] = {\"train\": train, \"val\": val, \"test\": test}\n",
        "\n",
        "    return language_data\n",
        "\n",
        "# Download and store data\n",
        "low_resource_datasets = load_wikiann_datasets(BaseConfig.low_resource_langs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.2 NER Dataset <a id='ner-dataset'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NERDataset:\n",
        "    def __init__(self, texts, tags, include_sentence = False):\n",
        "        self.texts = texts\n",
        "        self.tags = tags\n",
        "\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(\n",
        "            \"google-bert/bert-base-multilingual-cased\", do_lower_case = True\n",
        "        )\n",
        "\n",
        "        self.CLS_TOKEN = [101]\n",
        "        self.SEP_TOKEN = [102]\n",
        "        self.PAD_TOKEN = [0]\n",
        "        self.MAX_LEN = BaseConfig.MAX_SEQ_LEN\n",
        "\n",
        "        # Determines if the original sentence is returned for each batch\n",
        "        self.include_sentence = include_sentence\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[index]\n",
        "        tags = self.tags[index]\n",
        "\n",
        "        token_ids = []\n",
        "        target_tags = []\n",
        "        for i, word in enumerate(text):\n",
        "            word_ids = self.tokenizer.encode(word, add_special_tokens = False)\n",
        "            token_ids.extend(word_ids)\n",
        "            target_tags.extend(len(word_ids) * [tags[i]])\n",
        "\n",
        "        # Resize for special tokens\n",
        "        token_ids = token_ids[:self.MAX_LEN - 2]\n",
        "        target_tags = target_tags[:self.MAX_LEN - 2]\n",
        "\n",
        "        # Add special tokens\n",
        "        token_ids = self.CLS_TOKEN + token_ids + self.SEP_TOKEN\n",
        "        target_tags = self.PAD_TOKEN + target_tags + self.PAD_TOKEN\n",
        "\n",
        "        attention_mask = [1] * len(token_ids)\n",
        "        token_type_ids = [0] * len(token_ids)\n",
        "\n",
        "        # Add padding to make sure all inputs are the same size\n",
        "        padding_len = self.MAX_LEN - len(token_ids)\n",
        "        token_ids += [0] * padding_len\n",
        "        target_tags += [0] * padding_len\n",
        "        attention_mask += [0] * padding_len\n",
        "        token_type_ids += [0] * padding_len\n",
        "\n",
        "        if self.include_sentence:\n",
        "            return {\n",
        "                \"input_ids\": torch.tensor(token_ids, dtype = torch.long),\n",
        "                \"target_tags\": torch.tensor(target_tags, dtype = torch.long),\n",
        "                \"attention_mask\": torch.tensor(attention_mask, dtype = torch.long),\n",
        "                \"token_type_ids\": torch.tensor(token_type_ids, dtype = torch.long),\n",
        "                \"orginal_text\": \" \".join(text)\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(token_ids, dtype = torch.long),\n",
        "            \"target_tags\": torch.tensor(target_tags, dtype = torch.long),\n",
        "            \"attention_mask\": torch.tensor(attention_mask, dtype = torch.long),\n",
        "            \"token_type_ids\": torch.tensor(token_type_ids, dtype = torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.3 Dataloaders <a id='dataloaders'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dataloader(lang_split_data, include_sentence=False):\n",
        "    dataset = NERDataset(\n",
        "        lang_split_data[\"tokens\"].to_list(),\n",
        "        lang_split_data[\"ner_tags\"].to_list(),\n",
        "        include_sentence = include_sentence\n",
        "    )\n",
        "    return DataLoader(dataset, BaseConfig.BATCH_SIZE)\n",
        "\n",
        "def create_dataloaders(lang_data):\n",
        "\n",
        "    train_loader = create_dataloader(lang_data[\"train\"])\n",
        "    val_loader = create_dataloader(lang_data[\"val\"])\n",
        "    test_loader = create_dataloader(lang_data[\"test\"])\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Model Architecture <a id='model-architecture'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BertBilstmCrf(nn.Module):\n",
        "    def __init__(self, num_tags):\n",
        "        super(BertBilstmCrf, self).__init__()\n",
        "\n",
        "        # Define model layers\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size = self.bert.config.hidden_size,\n",
        "            hidden_size = 128,\n",
        "            num_layers = 2,\n",
        "            bidirectional = True,\n",
        "            batch_first = True,\n",
        "            dropout = 0.3\n",
        "        )\n",
        "        self.fc = nn.Linear(in_features = 256, out_features = num_tags)\n",
        "        self.crf = CRF(num_tags, batch_first = True)\n",
        "\n",
        "    @torch.autocast(device_type=\"cuda\")\n",
        "    def forward(self, input_ids, target_tags, attention_mask, token_type_ids):\n",
        "        # Pass inputs through layers\n",
        "        bert_output = self.bert(input_ids, attention_mask, token_type_ids)\n",
        "        sequence_output = bert_output.last_hidden_state\n",
        "        lstm_output, _ = self.lstm(sequence_output)\n",
        "        emissions = self.fc(lstm_output)\n",
        "\n",
        "        loss = -self.crf(emissions, target_tags, mask = attention_mask.bool(), reduction = \"mean\")\n",
        "        return emissions, loss\n",
        "\n",
        "    def decode(self, emissions, attention_mask):\n",
        "        return self.crf.decode(emissions, mask = attention_mask.bool())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Training Utilities <a id='training-utilities'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.1 Optimizer Setup <a id='optimizer-setup'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_optimizer(model, CONFIG):\n",
        "    param_groups = []\n",
        "    # Check model layers and add appropiate learning rates\n",
        "    if hasattr(model, \"bert\"):\n",
        "        param_groups.append({\"params\" : model.bert.parameters(), \"lr\" : CONFIG.BERT_LEARNING_RATE})\n",
        "    if hasattr(model, \"lstm\"):\n",
        "        param_groups.append({\"params\" : model.lstm.parameters(), \"lr\" : CONFIG.LSTM_LEARNING_RATE})\n",
        "    if hasattr(model, \"crf\"):\n",
        "        param_groups.append({\"params\" : model.crf.parameters(), \"lr\" : CONFIG.CRF_LEARNING_RATE})\n",
        "    optimizer = optim.Adam(param_groups, weight_decay = CONFIG.WEIGHT_DECAY)\n",
        "\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.2 Evaluation Metric <a id='evaluation-metric'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_f1(target_tags, pred_tags, attention_mask):\n",
        "\n",
        "    if isinstance(pred_tags, list):\n",
        "        pred_tags = [sequence + [0] * (BaseConfig.MAX_SEQ_LEN - len(sequence)) for sequence in pred_tags]\n",
        "        pred_tags = torch.tensor(pred_tags).to(BaseConfig.DEVICE)\n",
        "\n",
        "    # Flatten batch results\n",
        "    target_tags = target_tags.view(-1)\n",
        "    pred_tags = pred_tags.view(-1)\n",
        "    attention_mask = attention_mask.view(-1)\n",
        "\n",
        "    # Filter out padding and special tokens\n",
        "    target_tags = target_tags[attention_mask == 1]\n",
        "    pred_tags = pred_tags[attention_mask == 1]\n",
        "\n",
        "    f1_micro = f1_score(target_tags.cpu(), pred_tags.cpu(), average=\"micro\")\n",
        "    return f1_micro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Training Pipeline <a id='training-pipeline'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6.1 Training Functions <a id='training-functions'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, train_loader, val_loader, CONFIG):\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"min\", factor = 0.1, patience = 5)\n",
        "\n",
        "    best_val_f1 = -float(\"inf\")\n",
        "    best_train_f1 = 0\n",
        "    patience_counter = CONFIG.PATIENCE\n",
        "\n",
        "    for _ in range(CONFIG.EPOCHS):\n",
        "        _, train_f1 = train_epoch(model, train_loader, optimizer)\n",
        "        val_loss, val_f1 = evaluate_epoch(model, val_loader)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Save state of best model\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_train_f1 = train_f1\n",
        "            patience_counter = CONFIG.PATIENCE\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "        else:\n",
        "            patience_counter -= 1\n",
        "\n",
        "        if patience_counter == 0:\n",
        "            break  # Stop training if model doesn't improve\n",
        "\n",
        "    # Delete to clear up memory\n",
        "    model.to(\"cpu\")\n",
        "    del optimizer, scheduler, model\n",
        "\n",
        "    # Clear cache\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return best_model_state, best_train_f1, best_val_f1\n",
        "\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer):\n",
        "    model.train()\n",
        "    total_loss, total_f1 = 0, 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = {key : value.to(BaseConfig.DEVICE) for key, value in batch.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        emissions, loss = model(**batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        pred_tags = model.decode(emissions, batch[\"attention_mask\"])\n",
        "        f1_score = calculate_f1(batch[\"target_tags\"], pred_tags, batch[\"attention_mask\"])\n",
        "        total_f1 += f1_score\n",
        "\n",
        "    return total_loss / len(dataloader), total_f1 / len(dataloader)\n",
        "\n",
        "def evaluate_epoch(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss, total_f1 = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {key : value.to(BaseConfig.DEVICE) for key, value in batch.items()}\n",
        "\n",
        "            emissions, loss = model(**batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            pred_tags = model.decode(emissions, batch[\"attention_mask\"])\n",
        "            f1_score = calculate_f1(batch[\"target_tags\"], pred_tags, batch[\"attention_mask\"])\n",
        "            total_f1 += f1_score\n",
        "\n",
        "    return total_loss / len(dataloader), total_f1 / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6.2 Pseudo-labeling Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_pseudo_labeling(model, optimizer, train_loader, val_loader, unlabeled_data, CONFIG):\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"min\", factor = 0.1, patience = 5)\n",
        "\n",
        "    best_val_f1 = -float(\"inf\")\n",
        "    best_train_f1 = 0\n",
        "    patience_counter = CONFIG.PATIENCE\n",
        "\n",
        "    for epoch in range(CONFIG.EPOCHS):\n",
        "\n",
        "        _, train_f1 = train_epoch(model, train_loader, optimizer)\n",
        "        val_loss, val_f1 = evaluate_epoch(model, val_loader)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Save state of best model\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_train_f1 = train_f1\n",
        "            patience_counter = CONFIG.PATIENCE\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "        else:\n",
        "            patience_counter -= 1\n",
        "\n",
        "        if patience_counter == 0:\n",
        "            break  # Stop training if model doesn't improve\n",
        "\n",
        "        # Generate pseudo-labels with trained model on unlabeled data\n",
        "        pseudo_labels = generate_pseudo_labels(model, unlabeled_data)\n",
        "        confidence_threshold = pseudo_labels[\"confidence_score\"].quantile(CONFIG.CONFIDENCE_QUANTILE)\n",
        "\n",
        "        def filter_tags(row):\n",
        "            high_confidence = row[\"confidence_score\"] > confidence_threshold\n",
        "            # low_entropy = row[\"entropy\"] < CONFIG.ENTROPY_THRESHOLD\n",
        "            low_entropy = True\n",
        "            representative = set(row[\"ner_tags\"]) != {0}\n",
        "            same_length = len(row[\"tokens\"]) == len(row[\"ner_tags\"])\n",
        "            return high_confidence and low_entropy and representative and same_length\n",
        "\n",
        "        labels_to_keep = pseudo_labels.apply(filter_tags, axis=1)\n",
        "        good_pseudo_labels = pseudo_labels[labels_to_keep]\n",
        "        pseudo_labels = pseudo_labels[~labels_to_keep]\n",
        "\n",
        "        pseudo_dataset = NERDataset(good_pseudo_labels[\"tokens\"].tolist(), good_pseudo_labels[\"ner_tags\"].tolist())\n",
        "\n",
        "        if epoch > CONFIG.PSEUDO_DELAY:\n",
        "            existing_data = train_loader.dataset\n",
        "            combined_dataset = ConcatDataset([existing_data, pseudo_dataset])\n",
        "            train_loader = DataLoader(combined_dataset, CONFIG.BATCH_SIZE)\n",
        "            print(f\"Added {len(good_pseudo_labels)} rows of data\")\n",
        "        else:\n",
        "            print(\"Early epoch\")\n",
        "\n",
        "    # Delete to clear up memory\n",
        "    model.to(\"cpu\")\n",
        "    del optimizer, scheduler, model\n",
        "\n",
        "    # Clear cache\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return best_model_state, best_train_f1, best_val_f1\n",
        "\n",
        "\n",
        "def generate_pseudo_labels(model, unlabeled_data):\n",
        "\n",
        "    unlabeled_dataloader = create_dataloader(unlabeled_data, include_sentence=True)\n",
        "\n",
        "    # Initialize lists to store pseudo-labels and confidence scores\n",
        "    pseudo_sentences, pseudo_tags, pseudo_confidence_scores, entropy_scores = [], [], [], []\n",
        "\n",
        "    for batch in unlabeled_dataloader:\n",
        "        texts = batch[\"orginal_text\"]\n",
        "        texts = [text.split() for text in texts]\n",
        "        del batch[\"orginal_text\"]\n",
        "\n",
        "        batch = {key : value.to(BaseConfig.DEVICE) for key, value in batch.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            emissions, _ = model(**batch)\n",
        "            predicted_tags = model.decode(emissions, batch[\"attention_mask\"])\n",
        "\n",
        "            # Compute sequence probabilities and entropy\n",
        "            probs = F.softmax(emissions, dim=-1)\n",
        "            sequence_confidence_scores, sequence_entropies = [], []\n",
        "            for i, tags in enumerate(predicted_tags):\n",
        "                token_confidence = [probs[i, j, tag].item() for j, tag in enumerate(tags)]\n",
        "                token_entropy = -torch.sum(probs[i] * torch.log(probs[i] + 1e-9), dim=-1).cpu().numpy()\n",
        "\n",
        "                seq_confidence = sum(token_confidence) / len(token_confidence)\n",
        "                seq_entropy = sum(token_entropy) / len(token_entropy)\n",
        "                sequence_confidence_scores.append(seq_confidence)\n",
        "                sequence_entropies.append(seq_entropy)\n",
        "\n",
        "            predicted_tags = [\n",
        "                sequence[:BaseConfig.MAX_SEQ_LEN] + [0] * max(0, BaseConfig.MAX_SEQ_LEN - len(sequence))\n",
        "                for sequence in predicted_tags\n",
        "            ]\n",
        "\n",
        "            # Trim predicted tags\n",
        "            trimmed_predicted_tags = []\n",
        "            word_counts = [len(text) for text in texts]\n",
        "            for tag_seq, word_count in zip(predicted_tags, word_counts):\n",
        "                tag_seq = tag_seq[1:-1]\n",
        "                trimmed_predicted_tags.append(tag_seq[:word_count])\n",
        "\n",
        "            pseudo_sentences.extend(texts)\n",
        "            pseudo_tags.extend(trimmed_predicted_tags)\n",
        "            pseudo_confidence_scores.extend(sequence_confidence_scores)\n",
        "            entropy_scores.extend(sequence_entropies)\n",
        "\n",
        "    pseudo_df = pd.DataFrame({\n",
        "        \"tokens\": pseudo_sentences,\n",
        "        \"ner_tags\": pseudo_tags,\n",
        "        \"confidence_score\": pseudo_confidence_scores,\n",
        "        \"entropy\": entropy_scores\n",
        "    })\n",
        "\n",
        "    return pseudo_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxzyHtOLsuJ-"
      },
      "source": [
        "### 7. Experiments <a id='experiments'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7.1 Baseline Models <a id='baseline-models'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcqSTNMrXwIg",
        "outputId": "b4514c30-0861-407e-ebd6-e5d029b390a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████| 6/6 [04:31<00:00, 45.20s/it]\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "| language   |   train_f1 |   val_f1 |   test_f1 |\n",
              "|:-----------|-----------:|---------:|----------:|\n",
              "| mg         |   0.993728 | 0.933673 |  0.960352 |\n",
              "| fo         |   0.974224 | 0.897482 |  0.901099 |\n",
              "| co         |   0.956204 | 0.852308 |  0.81323  |\n",
              "| hsb        |   0.951443 | 0.923387 |  0.854578 |\n",
              "| bh         |   0.981549 | 0.888689 |  0.80212  |\n",
              "| cv         |   0.977741 | 0.892617 |  0.830443 |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "baseline_results = []\n",
        "\n",
        "# Iterate through low-resource languages\n",
        "for lang, lang_data in tqdm(low_resource_datasets.items(), ncols=80):\n",
        "\n",
        "    train_loader, val_loader, test_loader = create_dataloaders(lang_data)\n",
        "\n",
        "    # ------------------------------------------ TRAINING ------------------------------------------ #\n",
        "\n",
        "    model = BertBilstmCrf(BaseConfig.NUM_TAGS).to(BaseConfig.DEVICE)\n",
        "    optimizer = setup_optimizer(model, TrainConfig)\n",
        "    best_model_state, train_f1, val_f1 = train_model(model, optimizer, train_loader, val_loader, TrainConfig)\n",
        "\n",
        "    # ------------------------------------------ EVALUATION ------------------------------------------ #\n",
        "    eval_model = BertBilstmCrf(BaseConfig.NUM_TAGS).to(BaseConfig.DEVICE)\n",
        "    eval_model.load_state_dict(best_model_state, TrainConfig)\n",
        "    test_loss, test_f1 = evaluate_epoch(eval_model, test_loader, TrainConfig)\n",
        "\n",
        "    # ------------------------------------------ RESULTS ------------------------------------------ #\n",
        "    torch.save(best_model_state, f\"models/{lang}_baseline.pth\")\n",
        "\n",
        "    baseline_results.append({\n",
        "        \"language\" : lang,\n",
        "        \"train_f1\" : train_f1,\n",
        "        \"val_f1\"   : val_f1,\n",
        "        \"test_f1\"  : test_f1\n",
        "    })\n",
        "    \n",
        "# Save and display results\n",
        "baseline = pd.DataFrame(baseline_results)\n",
        "baseline.to_csv(\"results/baseline.csv\", index=False)\n",
        "\n",
        "markdown_table = baseline.to_markdown(index=False)\n",
        "display(Markdown(markdown_table))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline = pd.read_csv(\"results/baseline.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmv2uepyuddB"
      },
      "source": [
        "#### 7.2 Cross-Lingual Transfer Learning <a id='cross-lingual-transfer-learning'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfVbQr1wudOo",
        "outputId": "666c8b2c-5412-4d0f-b1e2-02a7f6a8c5c3"
      },
      "outputs": [],
      "source": [
        "transfer_results = []\n",
        "\n",
        "for augmentation_factor in tqdm(range(1, 24), ncols=80):\n",
        "\n",
        "    high_resource_datasets = load_wikiann_datasets(BaseConfig.high_resource_langs, augmentation_factor * 240)\n",
        "\n",
        "    # Iterate through low-resource and adjacent high-resource languages\n",
        "    for (low_resource_lang, low_resource_data), (high_resource_lang, high_resource_data) in tqdm(zip(\n",
        "            low_resource_datasets.items(), high_resource_datasets.items()\n",
        "        ), ncols=80, leave=False):\n",
        "\n",
        "        high_train_loader, high_val_loader, _ = create_dataloaders(high_resource_data)\n",
        "        low_train_loader, low_val_loader, low_test_loader = create_dataloaders(low_resource_data)\n",
        "\n",
        "        # ------------------------------------------ PRE-TRAINING ------------------------------------------ #\n",
        "\n",
        "        high_resource_model = BertBilstmCrf(BaseConfig.NUM_TAGS).to(BaseConfig.DEVICE)\n",
        "        optimizer = setup_optimizer(high_resource_model, TrainConfig)\n",
        "\n",
        "        high_resource_model_state, train_f1, val_f1 = train_model(high_resource_model, optimizer, high_train_loader, high_val_loader, TrainConfig)\n",
        "\n",
        "        # ------------------------------------------ FINE-TUNING ------------------------------------------ #\n",
        "\n",
        "        model = BertBilstmCrf(BaseConfig.NUM_TAGS).to(BaseConfig.DEVICE)\n",
        "        model.load_state_dict(high_resource_model_state)\n",
        "        optimizer = setup_optimizer(model, FineTuneConfig)\n",
        "\n",
        "        best_model_state, train_f1, val_f1 = train_model(model, optimizer, low_train_loader, low_val_loader, FineTuneConfig)\n",
        "\n",
        "        # ------------------------------------------ EVALUATION ------------------------------------------ #\n",
        "\n",
        "        eval_model = BertBilstmCrf(BaseConfig.NUM_TAGS).to(BaseConfig.DEVICE)\n",
        "        eval_model.load_state_dict(best_model_state)\n",
        "        test_loss, test_f1 = evaluate_epoch(eval_model, low_test_loader)\n",
        "\n",
        "        # ------------------------------------------ RESULTS ------------------------------------------ #\n",
        "        torch.save(best_model_state, f\"models/{low_resource_lang}_{high_resource_lang}_transfer.pth\")\n",
        "\n",
        "        baseline_performance = baseline.loc[baseline[\"language\"] == low_resource_lang, \"test_f1\"].item()\n",
        "        improvement = (test_f1 - baseline_performance) / baseline_performance * 100\n",
        "\n",
        "        transfer_results.append({\n",
        "            \"high_resource_language\" : high_resource_lang,\n",
        "            \"low_resource_lang\"      : low_resource_lang,\n",
        "            \"augmentation_factor\"    : augmentation_factor,\n",
        "            \"train_f1\"               : train_f1,\n",
        "            \"val_f1\"                 : val_f1,\n",
        "            \"test_f1\"                : test_f1,\n",
        "            \"improvement\"            : improvement\n",
        "        })\n",
        "\n",
        "        print(f\"Aug: {augmentation_factor}  {low_resource_lang} Improvement over baseline: {improvement:.5f}\")\n",
        "\n",
        "transfer_data = pd.DataFrame(transfer_results)\n",
        "transfer_data.to_csv(\"results/transfer_learning.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7.3 Iterative Pseudo-labeling <a id='iterative-pseudo-labeling'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iterative_pseudo_labeling_results = []\n",
        "\n",
        "# Iterate through low-resource languages\n",
        "high_resource_datasets = load_wikiann_datasets(BaseConfig.high_resource_langs, 10000)\n",
        "\n",
        "# Iterate through low-resource and adjacent high-resource languages\n",
        "for (lang, low_resource_data), (_, high_resource_data) in tqdm(zip(\n",
        "        low_resource_datasets.items(), high_resource_datasets.items()\n",
        "    ), ncols=80, leave=False):\n",
        "\n",
        "    train_loader, val_loader, test_loader = create_dataloaders(low_resource_data)\n",
        "    unlabeled_data = high_resource_data[\"train\"]\n",
        "\n",
        "    # ------------------------------------------ TRAINING ------------------------------------------ #\n",
        "\n",
        "    model = BertBilstmCrf(BaseConfig.NUM_TAGS).to(BaseConfig.DEVICE)\n",
        "    model.load_state_dict(torch.load(f\"models/{lang}_baseline.pth\"))\n",
        "    optimizer = setup_optimizer(model, PseudoLabelingConfig)\n",
        "    best_model_state, train_f1, val_f1 = train_pseudo_labeling(model, optimizer, train_loader, val_loader, unlabeled_data, PseudoLabelingConfig)\n",
        "\n",
        "    # ------------------------------------------ EVALUATION ------------------------------------------ #\n",
        "    \n",
        "    eval_model = BertBilstmCrf(BaseConfig.NUM_TAGS).to(BaseConfig.DEVICE)\n",
        "    eval_model.load_state_dict(best_model_state)\n",
        "    test_loss, test_f1 = evaluate_epoch(eval_model, test_loader)\n",
        "\n",
        "    # ------------------------------------------ RESULTS ------------------------------------------ #\n",
        "    torch.save(best_model_state, f\"models/{lang}_iterative_pseudo_labeling.pth\")\n",
        "\n",
        "    baseline_performance = baseline.loc[baseline[\"language\"] == lang, \"test_f1\"].item()\n",
        "    improvement = (test_f1 - baseline_performance) / baseline_performance * 100\n",
        "\n",
        "    iterative_pseudo_labeling_results.append({\n",
        "        \"language\"    : lang,\n",
        "        \"train_f1\"    : train_f1,\n",
        "        \"val_f1\"      : val_f1,\n",
        "        \"test_f1\"     : test_f1,\n",
        "        \"improvement\" : improvement\n",
        "    })\n",
        "\n",
        "    print(f\"Language: {lang}    Improvement over baseline: {improvement:.5f}\")\n",
        "\n",
        "\n",
        "# Save results\n",
        "iterative_pseudo_labeling = pd.DataFrame(iterative_pseudo_labeling_results)\n",
        "iterative_pseudo_labeling.to_csv(\"results/iterative_pseudo_labeling.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "multi-ner",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
